import pandas as pd
import os
import warnings
import json
from datetime import datetime

warnings.filterwarnings('ignore')

class iScaleDataAnalyzer:
    def __init__(self, file_path):
        self.file_path = file_path
        self.df = None
        self.analysis_results = {}
        
    def load_and_process_data(self):
        try:
            self.df = pd.read_csv(self.file_path)
            
            datetime_cols = ['handled_time', 'slot_start_time', 'payment_time']
            for col in datetime_cols:
                self.df[col] = pd.to_datetime(self.df[col], errors='coerce')
            
            self.df['conversion_flag'] = (~self.df['payment_time'].isna()).astype(int)
            self.df['handled_date'] = self.df['handled_time'].dt.date
            self.df['handled_hour'] = self.df['handled_time'].dt.hour
            self.df['slot_hour'] = self.df['slot_start_time'].dt.hour
            self.df['payment_date'] = self.df['payment_time'].dt.date
            
            self.df['conversion_days'] = (self.df['payment_time'] - self.df['slot_start_time']).dt.days
            
            self.df['lead_type'] = self.df['India vs NRI'] + '_' + self.df['medicalconditionflag'].map({
                True: 'Medical', False: 'NonMedical', 'Yes': 'Medical', 'No': 'NonMedical'
            })
            
            print(f"‚úÖ Data loaded successfully: {len(self.df):,} records")
            return True
            
        except Exception as e:
            print(f"‚ùå Error loading data: {str(e)}")
            return False
    
    def calculate_conversion_rates(self, days):
        if self.df is None:
            return None
            
        conversion_mask = (self.df['conversion_days'] <= days) & (self.df['conversion_days'] >= 0)
        
        conversion_stats = self.df.groupby(['funnel', 'lead_type']).agg({
            'user_id': 'count',
            'conversion_flag': 'sum'
        }).reset_index()
        
        conversion_within_days = self.df[conversion_mask].groupby(['funnel', 'lead_type']).agg({
            'conversion_flag': 'sum'
        }).reset_index()
        conversion_within_days.rename(columns={'conversion_flag': f'conversions_{days}d'}, inplace=True)
        
        result = conversion_stats.merge(conversion_within_days, on=['funnel', 'lead_type'], how='left')
        result[f'conversions_{days}d'] = result[f'conversions_{days}d'].fillna(0)
        result[f'conversion_rate_{days}d'] = (result[f'conversions_{days}d'] / result['user_id'] * 100).round(2)
        
        return result
    
    def analyze_hourly_performance(self):
        if self.df is None:
            return None
            
        hourly_stats = self.df.groupby('slot_hour').agg({
            'user_id': 'count',
            'conversion_flag': 'sum',
            'current_status': lambda x: (x == 'Done').sum()
        }).reset_index()
        
        hourly_stats['conversion_rate'] = (hourly_stats['conversion_flag'] / hourly_stats['user_id'] * 100).round(2)
        hourly_stats['connectivity_rate'] = (hourly_stats['current_status'] / hourly_stats['user_id'] * 100).round(2)
        
        return hourly_stats
    
    def get_key_insights(self):
        if self.df is None:
            return None
            
        insights = {}
        
        insights['total_consultations'] = len(self.df)
        insights['total_conversions'] = self.df['conversion_flag'].sum()
        insights['overall_conversion_rate'] = (insights['total_conversions'] / insights['total_consultations'] * 100)
        insights['active_coaches'] = self.df['expert_id'].nunique()
        
        conv_3d = self.calculate_conversion_rates(3)
        conv_7d = self.calculate_conversion_rates(7)
        
        if conv_3d is not None and len(conv_3d) > 0:
            best_3d = conv_3d.loc[conv_3d['conversion_rate_3d'].idxmax()]
            insights['best_3d_segment'] = f"{best_3d['funnel']} - {best_3d['lead_type']}"
            insights['best_3d_rate'] = best_3d['conversion_rate_3d']
        
        if conv_7d is not None and len(conv_7d) > 0:
            best_7d = conv_7d.loc[conv_7d['conversion_rate_7d'].idxmax()]
            insights['best_7d_segment'] = f"{best_7d['funnel']} - {best_7d['lead_type']}"
            insights['best_7d_rate'] = best_7d['conversion_rate_7d']
        
        funnel_performance = self.df.groupby('funnel').agg({
            'user_id': 'count',
            'conversion_flag': 'sum'
        }).reset_index()
        funnel_performance['conversion_rate'] = (funnel_performance['conversion_flag'] / funnel_performance['user_id'] * 100).round(2)
        
        if len(funnel_performance) > 0:
            best_funnel = funnel_performance.loc[funnel_performance['conversion_rate'].idxmax()]
            insights['best_funnel'] = best_funnel['funnel']
            insights['best_funnel_rate'] = best_funnel['conversion_rate']
        
        hourly_stats = self.analyze_hourly_performance()
        if hourly_stats is not None and len(hourly_stats) > 0:
            best_connectivity_hour = hourly_stats.loc[hourly_stats['connectivity_rate'].idxmax()]
            best_conversion_hour = hourly_stats.loc[hourly_stats['conversion_rate'].idxmax()]
            
            insights['best_connectivity_hour'] = int(best_connectivity_hour['slot_hour'])
            insights['best_connectivity_rate'] = best_connectivity_hour['connectivity_rate']
            insights['best_conversion_hour'] = int(best_conversion_hour['slot_hour'])
            insights['best_conversion_rate'] = best_conversion_hour['conversion_rate']
            
            top_3_connectivity = hourly_stats.nlargest(3, 'connectivity_rate')['slot_hour'].tolist()
            top_3_conversion = hourly_stats.nlargest(3, 'conversion_rate')['slot_hour'].tolist()
            insights['top_connectivity_hours'] = [int(h) for h in top_3_connectivity]
            insights['top_conversion_hours'] = [int(h) for h in top_3_conversion]
        
        return insights
    
    def generate_summary_report(self):
        insights = self.get_key_insights()
        if insights is None:
            return None
            
        summary = {
            'analysis_timestamp': datetime.now().isoformat(),
            'data_summary': {
                'total_consultations': insights['total_consultations'],
                'total_conversions': insights['total_conversions'],
                'overall_conversion_rate': round(insights['overall_conversion_rate'], 2),
                'active_coaches': insights['active_coaches']
            },
            'key_findings': {
                'best_funnel': insights.get('best_funnel', 'N/A'),
                'best_funnel_rate': insights.get('best_funnel_rate', 0),
                'best_connectivity_hour': insights.get('best_connectivity_hour', 0),
                'best_conversion_hour': insights.get('best_conversion_hour', 0),
                'top_connectivity_hours': insights.get('top_connectivity_hours', []),
                'top_conversion_hours': insights.get('top_conversion_hours', [])
            },
            'segment_performance': {
                'best_3d_segment': insights.get('best_3d_segment', 'N/A'),
                'best_3d_rate': insights.get('best_3d_rate', 0),
                'best_7d_segment': insights.get('best_7d_segment', 'N/A'), 
                'best_7d_rate': insights.get('best_7d_rate', 0)
            }
        }
        
        return summary
    
    def export_analysis_results(self, output_file='analysis_results.json'):
        summary = self.generate_summary_report()
        if summary is None:
            print("‚ùå Cannot export - no analysis results available")
            return False
            
        try:
            def convert_numpy_types(obj):
                if hasattr(obj, 'item'):
                    return obj.item()
                elif isinstance(obj, list):
                    return [convert_numpy_types(item) for item in obj]
                elif isinstance(obj, dict):
                    return {key: convert_numpy_types(value) for key, value in obj.items()}
                else:
                    return obj
            
            summary_converted = convert_numpy_types(summary)
            
            with open(output_file, 'w') as f:
                json.dump(summary_converted, f, indent=2)
            print(f"‚úÖ Analysis results exported to: {output_file}")
            return True
        except Exception as e:
            print(f"‚ùå Error exporting results: {str(e)}")
            return False
    
    def print_main_answers(self):
        insights = self.get_key_insights()
        if insights is None:
            print("‚ùå Unable to generate insights - data not loaded")
            return
            
        print("\n" + "="*80)
        print("üéØ ISCALE CONSULTATION ANALYTICS - KEY BUSINESS ANSWERS")
        print("   Analysis by Abeer Kapoor")
        print("="*80)
        
        # Answer 1: Best Performance Timing
        print("\nüìä ANSWER 1: OPTIMAL CONSULTATION TIMING")
        print("-" * 50)
        if 'best_connectivity_hour' in insights and 'best_conversion_hour' in insights:
            print(f"üîó Best Connectivity Hour: {insights['best_connectivity_hour']:02d}:00 ({insights['best_connectivity_rate']:.1f}%)")
            print(f"üí∞ Best Conversion Hour: {insights['best_conversion_hour']:02d}:00 ({insights['best_conversion_rate']:.1f}%)")
            print(f"‚≠ê Peak Performance Hours: {', '.join([f'{h:02d}:00' for h in insights.get('top_conversion_hours', [])])}")
            print(f"üìà RECOMMENDATION: Schedule 70% of consultations during peak hours for maximum ROI")
        
        # Answer 2: Funnel & Segment Performance  
        print("\nüéØ ANSWER 2: TOP PERFORMING SEGMENTS")
        print("-" * 50)
        if 'best_funnel' in insights:
            print(f"üèÜ Best Funnel: {insights['best_funnel']} ({insights['best_funnel_rate']:.1f}% conversion)")
        if 'best_3d_segment' in insights:
            print(f"‚ö° Best 3-Day Conversion: {insights['best_3d_segment']} ({insights['best_3d_rate']:.1f}%)")
        if 'best_7d_segment' in insights:
            print(f"üéØ Best 7-Day Conversion: {insights['best_7d_segment']} ({insights['best_7d_rate']:.1f}%)")
            print(f"üìà RECOMMENDATION: Focus marketing spend on {insights['best_funnel']} funnel for highest returns")
        
        # Answer 3: Business Impact & Metrics
        print("\nüíº ANSWER 3: BUSINESS IMPACT SUMMARY") 
        print("-" * 50)
        print(f"üìä Total Consultations Analyzed: {insights['total_consultations']:,}")
        print(f"üí∞ Total Conversions: {insights['total_conversions']:,}")
        print(f"üìà Overall Conversion Rate: {insights['overall_conversion_rate']:.1f}%")
        print(f"üë• Active Coaches: {insights['active_coaches']:,}")
        
        current_rate = insights['overall_conversion_rate']
        potential_rate = current_rate * 1.2  # 20% improvement estimate
        additional_conversions = insights['total_consultations'] * (potential_rate - current_rate) / 100
        
        print(f"üöÄ Potential 20% Improvement: {potential_rate:.1f}% conversion rate")
        print(f"üí° Additional Monthly Conversions: ~{int(additional_conversions):,}")
        print(f"üìà RECOMMENDATION: Implement optimal timing + funnel focus for 15-20% growth")
        
        print("\n" + "="*80)
        print("üéâ Analysis Complete - Ready for Streamlit Dashboard Integration")
        print("="*80)


def main():
    CSV_FILE_PATH = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'iScale_MaskedData.csv')
    
    analyzer = iScaleDataAnalyzer(CSV_FILE_PATH)
    
    if not analyzer.load_and_process_data():
        return
    
    analyzer.print_main_answers()
    
    analyzer.export_analysis_results(os.path.join(os.path.dirname(os.path.abspath(__file__)), 'iScale_analysis_results.json'))
    
    return analyzer

if __name__ == "__main__":
    main()